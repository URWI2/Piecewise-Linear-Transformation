# General
This repository contains the code for the paper "Piecewise Linear Transformation: Propagating Aleatoric Uncertainty in Neural Networks" presented at the 38th Annual AAAI Conference on Artificial Intelligence.
# Description of Code
This is a short description of the different parts of our Code. If you only think about using the Code, have a look at the small introduction given below.
* The 'Exactness.py' script is the evaluation code of this paper and applies the different methods for propagating uncertainty through a neural network as presented in the evaluation of our paper.
* The 'imputation.py' script is used to induce the desired uncertainty onto the input of the neural network. To this end, data is deleted in configurable quantities and replaced by probability distributions generated by multiple imputation and kernel density estimation. Finally, the uncertain data object is saved as a (cloud) pickle file.
* The 'Get_Sample_Baseline.py' script generates the baseline output distributions of the neural network by running large scale Monte Carlo Simulations. The resulting output distribution again is saved as a pickle file.
* The 'Polytopes.py' script contains the Python classes 'Polytope' and 'CPU' (convex polytope union). In this approach, they are used to model a single convex polytope and a union of these polytopes respectively, which both are needed for the piecewise linear representation of a neural network. The Polytope class contains two methods for dividing it into simplices of smaller size to obtain a fine-grained grid for the approximation of probability distributions, according to the procedure in the paper.
* The 'distribution.py' script contains the distribution class, which models a probability distribution on a convex polytope union, and useful methods on it, such as the baseline histogram generation method, which is called in the 'Get_Sample_Baseline.py' script. It also contains the key function for evaluating of our method for generating the output distribution at a single output point as well as the 'global_method' function, which is our implementation of the PLT method presented in the paper.
* The 'Linear_Segments.py' script contains our custom 'Model' class for a neural network and the corresponding 'propagate' method. It also contains the 'loadModel' function, that loads a model, saved as a .pt file, and initializes a corresponding 'Model' instance.
# How to use the Code
If you think about using this code to analyze your own problem settings, here is a basic introduction:
1. Bring the model you want to use into the correct form. For this you need to save it as a .pt file in a specific format. The best way to do this is to look at the models we saved in the provided dataset folders or to look at the 'loadModel' function in 'Linear_Segments.py' and reverse engineer the desired structure.
2. Next you should save your desired dataset as an .npy file in your dataset/data folder. This file should include both a numpy array containing the dataset X and a numpy array containing the labels y. The dataset X should be saved into the file first to ensure that X and y are loaded correctly in later steps. 
3. Now you can induce the desired uncertainty on the data by applying the 'imputation.py' dataset. This will delete certain data entries in your dataset and save the resulting dataset and the pdfs describing the uncertainty in the correct format for future use in your dataset/data folder. If the uncertainty in your data is already given, you can define a distribution class with the respective pdf instead.
4. If the exactness of the propagation should be assessed, one now has to use the 'Get_Sample_Baseline.py' script to generate the baseline output distributions via large scale Monte Carlo Simulations. They will be saved in the correct format for the evaluation under dataset/histos.
5. You are now ready to apply the 'Exactness.py' script, which propagates the uncertainty through your neural network via PLT. You can also employ the competing methods from our experiments and save all results to your dataset/results folder in the form of pickle files.
